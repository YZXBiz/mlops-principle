{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Operations (MLOps): Overview, Definition, and Architecture\n",
    "\n",
    "## Authors\n",
    "- Dominik Kreuzberger (KIT, Germany)\n",
    "- Niklas Kühl (KIT, Germany)\n",
    "- Sebastian Hirschl (IBM, Germany)\n",
    "\n",
    "## Abstract\n",
    "\n",
    "The final goal of all industrial machine learning (ML) projects is to develop ML products and rapidly bring them into production. However, it is highly challenging to automate and operationalize ML products and thus many ML endeavors fail to deliver on their expectations. The paradigm of Machine Learning Operations (MLOps) addresses this issue.\n",
    "\n",
    "This notebook provides a comprehensive overview of MLOps principles, components, roles, and architecture based on a mixed-method research study including literature review, tool review, and expert interviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Machine Learning (ML) has become an important technique to leverage the potential of data and allows businesses to be more innovative, efficient, and sustainable. However, the success of many productive ML applications in real-world settings falls short of expectations.\n",
    "\n",
    "### Key Challenges\n",
    "- Many ML projects fail to progress from proof of concept to production\n",
    "- Data scientists manually manage ML workflows to a great extent\n",
    "- Lack of automation and operationalization of ML systems\n",
    "- Complex ML system components and infrastructure coordination\n",
    "\n",
    "### Research Question\n",
    "**What is MLOps?**\n",
    "\n",
    "This research aims to:\n",
    "1. Identify important principles of MLOps\n",
    "2. Carve out functional core components\n",
    "3. Highlight necessary roles for successful MLOps implementation\n",
    "4. Derive a general architecture for ML systems design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Foundations of DevOps\n",
    "\n",
    "DevOps emerged in 2008/2009 as a paradigm addressing social and technical issues in software development organizations.\n",
    "\n",
    "### DevOps Goals\n",
    "- Eliminate the gap between development and operations\n",
    "- Emphasize collaboration, communication, and knowledge sharing\n",
    "- Ensure automation with CI/CD (Continuous Integration/Continuous Delivery/Continuous Deployment)\n",
    "- Enable fast, frequent, and reliable releases\n",
    "- Continuous testing, quality assurance, monitoring, logging, and feedback loops\n",
    "\n",
    "### DevOps Tools Categories\n",
    "1. **Collaboration and knowledge sharing** (e.g., Slack, Trello, GitLab wiki)\n",
    "2. **Source code management** (e.g., GitHub, GitLab)\n",
    "3. **Build process** (e.g., Maven)\n",
    "4. **Continuous integration** (e.g., Jenkins, GitLab CI)\n",
    "5. **Deployment automation** (e.g., Kubernetes, Docker)\n",
    "6. **Monitoring and logging** (e.g., Prometheus, Logstash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Research Methodology\n",
    "\n",
    "This study employed a mixed-method approach consisting of:\n",
    "\n",
    "### 3.1 Literature Review\n",
    "- Systematic review following Webster and Watson methodology\n",
    "- Search query: ((\"DevOps\" OR \"CICD\" OR \"Continuous Integration\" OR \"Continuous Delivery\" OR \"Continuous Deployment\") AND \"Machine Learning\") OR \"MLOps\" OR \"CD4ML\"\n",
    "- Databases: Google Scholar, Web of Science, Science Direct, Scopus, AIS eLibrary\n",
    "- **Results**: 1,864 retrieved articles → 194 screened → 27 selected peer-reviewed articles\n",
    "\n",
    "### 3.2 Tool Review\n",
    "- Analysis of open-source tools, frameworks, and commercial cloud ML services\n",
    "- 11 tools evaluated for technical components understanding\n",
    "\n",
    "### 3.3 Interview Study\n",
    "- Semi-structured expert interviews with theoretical sampling\n",
    "- **8 interviews** with ML professionals from different organizations, industries, and countries\n",
    "- Interviews conducted until theoretical saturation was reached\n",
    "- Open coding scheme used for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MLOps Principles\n",
    "\n",
    "Based on the research methodology, **9 core principles** were identified for realizing MLOps:\n",
    "\n",
    "### P1: CI/CD Automation\n",
    "- Provides continuous integration, continuous delivery, and continuous deployment\n",
    "- Carries out build, test, delivery, and deploy steps\n",
    "- Provides fast feedback to developers\n",
    "- Increases overall productivity\n",
    "\n",
    "### P2: Workflow Orchestration\n",
    "- Coordinates tasks of ML workflow pipeline according to directed acyclic graphs (DAGs)\n",
    "- DAGs define task execution order by considering relationships and dependencies\n",
    "\n",
    "### P3: Reproducibility\n",
    "- Ability to reproduce an ML experiment and obtain the exact same results\n",
    "- Essential for scientific validity and debugging\n",
    "\n",
    "### P4: Versioning\n",
    "- Ensures versioning of data, model, and code\n",
    "- Enables not only reproducibility but also traceability\n",
    "- Important for compliance and auditing reasons\n",
    "\n",
    "### P5: Collaboration\n",
    "- Ensures possibility to work collaboratively on data, model, and code\n",
    "- Emphasizes collaborative and communicative work culture\n",
    "- Aims to reduce domain silos between different roles\n",
    "\n",
    "### P6: Continuous ML Training & Evaluation\n",
    "- Periodic retraining of ML model based on new feature data\n",
    "- Enabled through monitoring component, feedback loop, and automated ML workflow pipeline\n",
    "- Always includes evaluation run to assess change in model quality\n",
    "\n",
    "### P7: ML Metadata Tracking/Logging\n",
    "- Tracks and logs metadata for each orchestrated ML workflow task\n",
    "- Includes training job iteration metadata (date, time, duration)\n",
    "- Tracks model-specific metadata (parameters, performance metrics, model lineage)\n",
    "- Ensures full traceability of experiment runs\n",
    "\n",
    "### P8: Continuous Monitoring\n",
    "- Periodic assessment of data, model, code, infrastructure resources\n",
    "- Monitors model serving performance (e.g., prediction accuracy)\n",
    "- Detects potential errors or changes that influence product quality\n",
    "\n",
    "### P9: Feedback Loops\n",
    "- Multiple feedback loops integrate insights from quality assessment into development\n",
    "- Feedback from experimental model engineering to feature engineering\n",
    "- Feedback from monitoring component to scheduler for retraining enablement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Technical Components\n",
    "\n",
    "The principles are implemented through **9 technical components**:\n",
    "\n",
    "### C1: CI/CD Component (P1, P6, P9)\n",
    "- Ensures continuous integration, delivery, and deployment\n",
    "- Handles build, test, delivery, and deploy steps\n",
    "- **Examples**: Jenkins, GitHub Actions\n",
    "\n",
    "### C2: Source Code Repository (P4, P5)\n",
    "- Ensures code storing and versioning\n",
    "- Allows multiple developers to commit and merge code\n",
    "- **Examples**: GitHub, GitLab, Bitbucket, Gitea\n",
    "\n",
    "### C3: Workflow Orchestration Component (P2, P3, P6)\n",
    "- Offers task orchestration via directed acyclic graphs (DAGs)\n",
    "- Represents execution order and artifact usage of workflow steps\n",
    "- **Examples**: Apache Airflow, Kubeflow Pipelines, Luigi, AWS SageMaker Pipelines\n",
    "\n",
    "### C4: Feature Store System (P3, P4)\n",
    "- Central storage of commonly used features\n",
    "- Offline database for experimentation (normal latency)\n",
    "- Online database for production predictions (low latency)\n",
    "- **Examples**: Google Feast, Amazon AWS Feature Store, Tecton.ai, Hopswork.ai\n",
    "\n",
    "### C5: Model Training Infrastructure (P6)\n",
    "- Provides foundational computation resources (CPUs, RAM, GPUs)\n",
    "- Can be distributed or non-distributed\n",
    "- Scalable and distributed infrastructure recommended\n",
    "- **Examples**: Local machines, cloud computation, Kubernetes, Red Hat OpenShift\n",
    "\n",
    "### C6: Model Registry (P3, P4)\n",
    "- Centrally stores trained ML models with metadata\n",
    "- Two main functionalities: storing ML artifacts and ML metadata\n",
    "- **Examples**: MLflow, AWS SageMaker Model Registry, Azure ML Model Registry, Neptune.ai\n",
    "\n",
    "### C7: ML Metadata Stores (P4, P7)\n",
    "- Tracks various kinds of metadata for ML workflow pipeline tasks\n",
    "- Stores training job metadata (date, time, duration, parameters, performance metrics)\n",
    "- Tracks model lineage (data and code used)\n",
    "- **Examples**: Kubeflow Pipelines, AWS SageMaker Pipelines, Azure ML, IBM Watson Studio\n",
    "\n",
    "### C8: Model Serving Component (P1)\n",
    "- Configured for different purposes: online inference or batch inference\n",
    "- Can serve via REST API\n",
    "- Scalable and distributed infrastructure recommended\n",
    "- **Examples**: Kubernetes + Docker + Flask, KServing, TensorFlow Serving, cloud services\n",
    "\n",
    "### C9: Monitoring Component (P8, P9)\n",
    "- Continuous monitoring of model serving performance\n",
    "- Monitors ML infrastructure, CI/CD, and orchestration\n",
    "- **Examples**: Prometheus + Grafana, ELK stack, TensorBoard, cloud monitoring services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. MLOps Roles\n",
    "\n",
    "MLOps requires **7 key roles** for successful implementation:\n",
    "\n",
    "### R1: Business Stakeholder\n",
    "- **Similar roles**: Product Owner, Project Manager\n",
    "- **Responsibilities**: Defines business goals, communicates ROI, presents business value\n",
    "\n",
    "### R2: Solution Architect\n",
    "- **Similar roles**: IT Architect\n",
    "- **Responsibilities**: Designs architecture, defines technologies after thorough evaluation\n",
    "\n",
    "### R3: Data Scientist\n",
    "- **Similar roles**: ML Specialist, ML Developer\n",
    "- **Responsibilities**: Translates business problems to ML problems, model engineering, algorithm and hyperparameter selection\n",
    "\n",
    "### R4: Data Engineer\n",
    "- **Similar roles**: DataOps Engineer\n",
    "- **Responsibilities**: Builds and manages data/feature engineering pipelines, ensures proper data ingestion to feature stores\n",
    "\n",
    "### R5: Software Engineer\n",
    "- **Responsibilities**: Applies software design patterns, coding guidelines, and best practices to turn raw ML problems into well-engineered products\n",
    "\n",
    "### R6: DevOps Engineer\n",
    "- **Responsibilities**: Bridges gap between development and operations, ensures CI/CD automation, ML workflow orchestration, model deployment, and monitoring\n",
    "\n",
    "### R7: ML Engineer/MLOps Engineer\n",
    "- **Cross-domain role** combining aspects of multiple roles\n",
    "- **Skills from**: Data scientists, data engineers, software engineers, DevOps engineers, backend engineers\n",
    "- **Responsibilities**: Builds and operates ML infrastructure, manages automated ML workflow pipelines, handles model deployment and monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. MLOps Architecture and Workflow\n",
    "\n",
    "The end-to-end MLOps architecture consists of **4 main stages**:\n",
    "\n",
    "### (A) MLOps Project Initiation\n",
    "1. **Business analysis** (R1): Identify potential business problems solvable with ML\n",
    "2. **Architecture design** (R2): Define overall ML system architecture and technologies\n",
    "3. **ML problem derivation** (R3): Derive ML problem from business goal\n",
    "4. **Data requirements** (R3, R4): Understand required data to solve the problem\n",
    "5. **Data source location** (R3, R4): Locate and analyze raw data sources\n",
    "\n",
    "### (B) Feature Engineering Pipeline\n",
    "\n",
    "#### B1: Requirements Definition\n",
    "6. **Data transformation rules** (R4): Define normalization, aggregations, cleaning rules\n",
    "7. **Feature engineering rules** (R3, R4): Define calculation of new features\n",
    "\n",
    "#### B2: Pipeline Implementation\n",
    "8. **Raw data connection**: Connect to streaming, batch, or cloud storage data\n",
    "9. **Data extraction**: Extract data from sources\n",
    "10. **Data preprocessing**: Transform and clean data\n",
    "11. **Feature engineering**: Calculate new features based on existing ones\n",
    "12. **Data ingestion**: Load data into feature store (offline/online databases)\n",
    "\n",
    "### (C) Experimentation\n",
    "13. **Data analysis** (R3): Connect to feature store for analysis\n",
    "14. **Data preparation** (R3): Prepare and validate data, create train/test splits\n",
    "15. **Algorithm selection** (R3): Estimate best-performing algorithm and hyperparameters\n",
    "16. **Model training** (R3, R5): Train and validate models iteratively\n",
    "17. **Model export** (R3): Export best-performing model and commit code\n",
    "\n",
    "### (D) Automated ML Workflow Pipeline\n",
    "18. **Data extraction**: Automated pulling of versioned features\n",
    "19. **Data preparation**: Automated data preparation and validation\n",
    "20. **Model training**: Automated final model training on new data\n",
    "21. **Model evaluation**: Automated model evaluation and hyperparameter adjustment\n",
    "22. **Model export**: Export trained model\n",
    "23. **Model registry**: Push model to registry with metadata\n",
    "24. **Deployment**: CI/CD triggers continuous deployment pipeline\n",
    "25. **Model serving**: Serve predictions on new data\n",
    "26. **Monitoring**: Continuous monitoring of model and infrastructure performance\n",
    "27. **Feedback loops**: Fast feedback for continuous improvement and retraining\n",
    "28. **Continuous training**: Trigger retraining based on monitoring feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. MLOps Definition\n",
    "\n",
    "Based on the research findings, MLOps is defined as:\n",
    "\n",
    "> **MLOps (Machine Learning Operations) is a paradigm, including aspects like best practices, sets of concepts, as well as a development culture when it comes to the end-to-end conceptualization, implementation, monitoring, deployment, and scalability of machine learning products.**\n",
    ">\n",
    "> **Most of all, it is an engineering practice that leverages three contributing disciplines: machine learning, software engineering (especially DevOps), and data engineering.**\n",
    ">\n",
    "> **MLOps is aimed at productionizing machine learning systems by bridging the gap between development (Dev) and operations (Ops).**\n",
    ">\n",
    "> **Essentially, MLOps aims to facilitate the creation of machine learning products by leveraging these principles: CI/CD automation, workflow orchestration, reproducibility; versioning of data, model, and code; collaboration; continuous ML training and evaluation; ML metadata tracking and logging; continuous monitoring; and feedback loops.**\n",
    "\n",
    "### Key Characteristics\n",
    "- **Paradigm**: More than just tools and technologies\n",
    "- **Interdisciplinary**: Combines ML, software engineering, and data engineering\n",
    "- **Engineering practice**: Focus on production-ready systems\n",
    "- **Bridge**: Connects development and operations\n",
    "- **Principle-driven**: Based on 9 core principles for automation and operationalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Open Challenges\n",
    "\n",
    "Several challenges for adopting MLOps have been identified:\n",
    "\n",
    "### 9.1 Organizational Challenges\n",
    "- **Mindset and culture shift**: From model-driven to product-oriented discipline\n",
    "- **Skills shortage**: Lack of highly skilled experts, especially architects, data engineers, ML engineers, DevOps engineers\n",
    "- **Education gap**: MLOps typically not part of data science education\n",
    "- **Team coordination**: Need for multi-disciplinary teams vs. working in silos\n",
    "- **Communication barriers**: Different knowledge levels and specialized terminologies\n",
    "- **Business buy-in**: Convincing decision-makers of MLOps maturity benefits\n",
    "\n",
    "### 9.2 ML System Challenges\n",
    "- **Fluctuating demand**: Designing for varying ML training processes\n",
    "- **Resource estimation**: Difficulty estimating infrastructure resources (CPU, RAM, GPU)\n",
    "- **Scalability requirements**: High level of flexibility needed for infrastructure scaling\n",
    "\n",
    "### 9.3 Operational Challenges\n",
    "- **Manual operations complexity**: Challenging to operate ML manually due to diverse software/hardware stacks\n",
    "- **Automation requirements**: Need for robust automation across the entire pipeline\n",
    "- **Continuous retraining**: Constant incoming data forces repetitive retraining tasks\n",
    "- **Artifact management**: Large number of artifacts require strong governance and versioning\n",
    "- **Support complexity**: Resolving issues complicated by many parties and components involved\n",
    "- **Failure diagnosis**: Failures can be combination of ML infrastructure and software issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Tools and Technologies\n",
    "\n",
    "### 10.1 Open-Source Examples\n",
    "\n",
    "| Tool | Description | Components |\n",
    "|------|-------------|------------|\n",
    "| **TensorFlow Extended (TFX)** | Configuration framework for end-to-end ML pipelines | Data validation, model training, serving |\n",
    "| **Apache Airflow** | Workflow orchestration tool using DAGs | Workflow orchestration |\n",
    "| **Kubeflow** | Kubernetes-based end-to-end ML platform | Complete MLOps platform |\n",
    "| **MLflow** | ML lifecycle management platform | Experiment tracking, model registry, serving |\n",
    "\n",
    "### 10.2 Commercial Examples\n",
    "\n",
    "| Platform | Description | Provider |\n",
    "|----------|-------------|----------|\n",
    "| **Amazon SageMaker** | End-to-end ML platform with feature store, pipelines, endpoints | AWS |\n",
    "| **Azure ML** | End-to-end ML platform with DevOps integration | Microsoft |\n",
    "| **Google Vertex AI** | Fully managed end-to-end ML platform | Google Cloud |\n",
    "| **IBM Watson Studio** | Data and ML capabilities package | IBM |\n",
    "| **Databricks** | Managed MLflow and ML platform | Databricks |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion\n",
    "\n",
    "This comprehensive study provides a holistic understanding of MLOps through:\n",
    "\n",
    "### Key Contributions\n",
    "1. **9 Core Principles** that guide MLOps implementation\n",
    "2. **9 Technical Components** that operationalize the principles\n",
    "3. **7 Essential Roles** required for successful MLOps adoption\n",
    "4. **End-to-end Architecture** with detailed workflow stages\n",
    "5. **Formal Definition** of MLOps as a paradigm\n",
    "6. **Open Challenges** categorized into organizational, system, and operational\n",
    "\n",
    "### Research Impact\n",
    "- Provides common understanding of MLOps terminology and concepts\n",
    "- Offers practical guidance for ML researchers and practitioners\n",
    "- Addresses the gap between ML model development and production deployment\n",
    "- Supports transition from manual ML workflows to automated, operationalized systems\n",
    "\n",
    "### Future Directions\n",
    "- Address identified challenges through targeted solutions\n",
    "- Develop MLOps education curricula\n",
    "- Create standardized MLOps maturity models\n",
    "- Investigate domain-specific MLOps adaptations\n",
    "- Explore automation techniques for complex ML workflows\n",
    "\n",
    "The paradigm of MLOps represents a fundamental shift toward engineering practices that enable reliable, scalable, and maintainable machine learning systems in production environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "This notebook is based on the research paper:\n",
    "\n",
    "**Kreuzberger, D., Kühl, N., & Hirschl, S.** \"Machine Learning Operations (MLOps): Overview, Definition, and Architecture.\" \n",
    "\n",
    "The original paper includes 46 references covering MLOps literature, DevOps foundations, workflow orchestration, continuous delivery for ML, and industry case studies.\n",
    "\n",
    "### Key Reference Categories\n",
    "- MLOps and continuous delivery for ML systems\n",
    "- DevOps principles and practices\n",
    "- Machine learning engineering and operations\n",
    "- Software engineering best practices\n",
    "- Cloud-based ML platforms and tools\n",
    "- Workflow orchestration and automation\n",
    "- Data engineering and feature stores\n",
    "- Model monitoring and deployment strategies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}